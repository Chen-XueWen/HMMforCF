{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HMMforCF_clean.ipynb","provenance":[{"file_id":"18mm9Pcn74YYmTpccJy-lWPF3M5ByrfbO","timestamp":1633762713237},{"file_id":"1v7vqEVkzjGbWDMR6Et_yXqG8OZv4ovdS","timestamp":1633758281591},{"file_id":"1c5sPR_6ZnojLorUgql_o_ZrjRawNQf_S","timestamp":1631338387917}],"collapsed_sections":["78tSnQTojYSg"],"mount_file_id":"11SWLML91N1kIcylqpfhbaOq12AIy6ugf","authorship_tag":"ABX9TyPOJwg/UZ6voSAT/nQBY5fD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"78tSnQTojYSg"},"source":["# Packages and Functions"]},{"cell_type":"code","metadata":{"id":"fEyqx4aCkAi1","executionInfo":{"status":"ok","timestamp":1634347760048,"user_tz":-480,"elapsed":285,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}}},"source":["import numpy as np\n","import pandas as pd\n","from scipy.stats import dirichlet\n","from scipy.special import logsumexp, gammaln, digamma, polygamma\n","from datetime import datetime\n","import pickle\n","from sklearn.preprocessing import MultiLabelBinarizer"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9uY1aJSfy4J","executionInfo":{"status":"ok","timestamp":1634347760836,"user_tz":-480,"elapsed":483,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}}},"source":["def logdotexp(A, B):\n","    max_A = np.max(A)\n","    max_B = np.max(B)\n","    C = np.dot(np.exp(A - max_A), np.exp(B - max_B))\n","    np.log(C, out=C)\n","    C += max_A + max_B\n","    return C"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jJWglv0Hi0Xd"},"source":["# Load List of Sparse Matrices"]},{"cell_type":"code","metadata":{"id":"wcnnSVuQi4L_","executionInfo":{"status":"ok","timestamp":1634347760837,"user_tz":-480,"elapsed":8,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}}},"source":["path = '/content/drive/MyDrive/PhD/Modules/IS6101 Topics in Machine Learning and Optimization/HMM for CF/Data and Parameters/'\n","users_ds = pickle.load(open(path + 'users_ds.pkl','rb'))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yD82afiPZ8k","executionInfo":{"status":"ok","timestamp":1634347760838,"user_tz":-480,"elapsed":8,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}},"outputId":"37a8a6b3-b40a-4487-b70b-f8af0c4bcd26"},"source":["U = len(users_ds)\n","T = users_ds[0].shape[0]\n","N = users_ds[0].shape[1]\n","U, T, N"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(874, 73, 17606)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"SW9OGXCgoMgZ","executionInfo":{"status":"ok","timestamp":1634347760838,"user_tz":-480,"elapsed":6,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}}},"source":["# test_ds = [user[-1,:] for user in users_ds]\n","# users_ds = [user[:-1,:] for user in users_ds]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqAzxZEiio3M","executionInfo":{"status":"ok","timestamp":1634347760838,"user_tz":-480,"elapsed":6,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}}},"source":["t_predict = -2\n","test_ds = [user[t_predict,:] for user in users_ds]\n","users_ds = [user[47:t_predict,:] for user in users_ds]"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJ6gmTioo1Ra","executionInfo":{"status":"ok","timestamp":1634347760839,"user_tz":-480,"elapsed":7,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}},"outputId":"ece297a9-0b91-4168-b43d-d1f303c4e603"},"source":["len(test_ds), test_ds[0].shape[0], test_ds[0].shape[1]"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(874, 1, 17606)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbSrH8FQovkO","executionInfo":{"status":"ok","timestamp":1634347760839,"user_tz":-480,"elapsed":6,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}},"outputId":"0f7bd870-6b59-4500-dd1c-bf7066774d97"},"source":["U = len(users_ds)\n","T = users_ds[0].shape[0]\n","N = users_ds[0].shape[1]\n","U, T, N"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(874, 24, 17606)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSfcTrkj06AF","executionInfo":{"status":"ok","timestamp":1634347761509,"user_tz":-480,"elapsed":675,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}},"outputId":"8cb81409-f71e-45f8-b7d8-a0cd1f703795"},"source":["# calculate and store total number of ratings per user in a period\n","\n","users_Nt = []\n","for i in range(len(users_ds)):\n","    user_sum = users_ds[i].sum(axis=-1)\n","    user_sum = np.array([row[0,0] for row in user_sum]) # for some reason, flatten/squeeze doesn't work\n","    users_Nt.append(user_sum)\n","    \n","len(users_Nt), users_Nt[0].shape"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(874, (24,))"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"iOLPcJ7fpnBR"},"source":["# Multiple runs on same settings"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYpo4SvIjWxh","executionInfo":{"status":"ok","timestamp":1634355700754,"user_tz":-480,"elapsed":7939246,"user":{"displayName":"Chung-I Lu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13493253019536068280"}},"outputId":"c5526ec3-975f-45f2-f0f7-a27474a31270"},"source":["for r in range(5):\n","    # Initial parameters\n","    K = 10 # no of latent classes\n","    prior_const = K-1 # affects the parameters of the Dirichlet priors\n","    pi_alpha = prior_const/K * np.ones((K)) # alpha hyperparams for pi\n","    A_alpha = prior_const/K * np.ones((K,K)) # alpha hyperparams for A\n","    theta_alpha = prior_const/K * np.ones((K,N)) # alpha hyperparams for theta\n","    a = np.random.uniform(low=2, high=5, size=(K)) # initialise parameter a randomly\n","    p = np.random.uniform(low=0.6, high=0.8, size=(K)) # initialise parameter p which corresponds to standard multinomial set up \n","    b = p / (1-p) # derive parameter b for the gamma mixture of poisson distribution which = NBD\n","\n","    pi = dirichlet.rvs(alpha=pi_alpha, size=1) # initialise pi randomly\n","    A = np.zeros((K,K)) \n","    theta = np.zeros((K,N))\n","    for k in range(K):\n","        A[k,:] = dirichlet.rvs(alpha=A_alpha[k,:], size=1) \n","        theta[k,:] = dirichlet.rvs(alpha=theta_alpha[k,:], size=1) \n","\n","    A = np.log(A)\n","    pi = np.log(pi)\n","    theta = np.log(theta)\n","\n","    # EM Algorithm\n","    start_time = datetime.now()\n","    epsilon = 1e-4\n","    a_epsilon = 1e-3\n","    old_likelihood = None\n","    iteration = 0\n","    while True:\n","        # initialise variables to store per user calculations\n","        init = 0\n","        trans = 0\n","        nbd = 0\n","        multi = 0\n","        N_bar = 0\n","        log_N_bar = 0\n","        user_class = np.empty((U,K))\n","        for u in range(U):\n","            # E STEP PER USER\n","\n","            dataset = np.array(users_ds[u].todense())\n","            N_t = np.array(users_Nt[u])\n","\n","            # log prob of N given z as gamma mixture of poisson i.e. number of articles read\n","            p_n_ab = gammaln(N_t[..., np.newaxis] + a[np.newaxis, ...]) \\\n","                    - gammaln(a)[np.newaxis, ...] - gammaln(N_t+1)[..., np.newaxis] \\\n","                    + N_t[..., np.newaxis] * np.log(b)[np.newaxis, ...]  \\\n","                    - (N_t[..., np.newaxis] + a[np.newaxis, ...]) * np.log(b+1)[np.newaxis, ...]\n","\n","            # log prob of I given z and N as Multinomial(theta) i.e. which articles are read where read=1/unread=0     \n","            p_i_theta = (gammaln(N_t+1) - gammaln(dataset+1).sum(axis=1))[..., np.newaxis] \\\n","                        + np.dot(dataset, theta.T)\n","\n","            # log prob of joint dist of N, I given z\n","            p_i_z = p_n_ab + p_i_theta\n","\n","            # HMM for CF paper definition of alpha and beta\n","            alpha = np.empty((T,K))\n","            p_i_i = np.empty((T))\n","\n","            alpha[0] = p_i_z[0] + pi\n","            alpha[0] -= logsumexp(alpha[0])\n","            for t in range(1, T):\n","                alpha[t] = logdotexp(alpha[t-1], A) + p_i_z[t]\n","                p_i_i[t] = logsumexp(alpha[t]) # normalization constant for alpha/beta/p_zz_i\n","                alpha[t] -= p_i_i[t]\n","\n","            beta = np.zeros((T,K))\n","            for t in range(-2, -1, -1):\n","                beta[t] = logdotexp(A, (p_i_z[t+1] + beta[t+1]))\n","                beta[t] -= p_i_i[t+1] # normalization\n","\n","            # calculate the posterior P(Z|I) \n","            p_z_i = alpha + beta\n","            user_class[u,:] = p_z_i[-1,:]\n","\n","            # calculate the transitional posterior P(Z(t-1), Z(t)|I)\n","            p_zz_i = np.zeros((T-1,K,K))\n","            for t in range(T-1):\n","                p_zz_i[t,:,:] = np.tile(alpha[t,:], (K,1)).T + A + np.tile(p_i_z[t+1,:], (K,1)) + np.tile(beta[t+1,:], (K,1)) \n","                p_zz_i[t,:,:] -= p_i_i[t+1][...,np.newaxis,np.newaxis] # normalization\n","\n","            # CALCULATE EXPECTED LOG LIKELIHOOD PER USER    \n","\n","            # intial state \n","            init += np.sum(np.exp(p_z_i[0]) * pi)\n","\n","            # transitional \n","            trans += np.sum(np.exp(p_zz_i) * A[np.newaxis,...])\n","\n","            # # of items \n","            nbd += np.sum(np.exp(p_z_i) * p_n_ab)\n","\n","            # specific item \n","            multi += np.sum(np.exp(p_z_i) * p_i_theta)\n","\n","            # M STEP PER USER\n","\n","            # update pi parameters using MAP\n","            pi_alpha += np.exp(p_z_i[0])\n","\n","            # update A parameters using MAP\n","            A_alpha += np.sum(np.exp(p_zz_i), axis=0)\n","\n","            # update theta parameters using MAP\n","            for k in range(K):\n","                theta_alpha[k,:] += np.sum(dataset * np.exp(p_z_i[:,k][...,np.newaxis]), axis=0)\n","\n","            # update a using MLE with Newton's method\n","            N_bar += np.sum((np.exp(p_z_i) * N_t[...,np.newaxis] + a[np.newaxis,...]) * (b / (b + 1))[np.newaxis,...], axis=0) / (U*T)\n","            log_N_bar += np.sum(digamma(np.exp(p_z_i) * N_t[...,np.newaxis] + a[np.newaxis,...]) + np.log(b / (b + 1))[np.newaxis,...], axis=0) / (U*T)\n","\n","        # CALCULATE EXPECTED LOG LIKELIHOOD FOR ALL USERS COMBINED\n","        # calculation done after posterior of latent class is calculated which means KL divergence=0\n","        # lower bound = evidence since q(z) = p(z|x)\n","        # check that it is increasing at every iteration and check for convergence condition\n","\n","        if old_likelihood is None:\n","            old_likelihood = init + trans + nbd + multi\n","        else:\n","            new_likelihood = init + trans + nbd + multi \n","            if np.isnan(new_likelihood):\n","                print('Numerical issues in calculation of log likelihood\\nPrevious calculated log likelihood = ', old_likelihood)\n","                break\n","            if new_likelihood < old_likelihood:\n","                print('Iteration resulted in lower log likelihood =', new_likelihood)\n","                break\n","            if np.abs((new_likelihood - old_likelihood) / old_likelihood) < epsilon:\n","                old_likelihood = new_likelihood\n","                print('Iteration', iteration,': log likelihood =', old_likelihood, '\\n')\n","                print('Convergence attained \\n')\n","                break\n","            old_likelihood = new_likelihood\n","        print('Iteration', iteration,': log likelihood =', old_likelihood)\n","        iteration += 1\n","\n","        # M STEP FOR ALL USERS\n","\n","        # update pi log prob using MAP with the parameters\n","        pi = (pi_alpha - 1) / (np.sum(pi_alpha) - K)\n","        pi = np.log(pi)\n","        \n","        # update A log prob using MAP with the parameters\n","        A = (A_alpha - 1) / (np.sum(A_alpha, axis=-1) - K)[...,np.newaxis] # to align the division\n","        A = np.log(A)\n","\n","        # update theta log prob using MAP with the parameters\n","        theta = theta_alpha / (np.sum(theta_alpha, axis=-1))[...,np.newaxis]\n","        theta = np.log(theta)\n","        \n","        # update a using MLE with Newton's method\n","        for _ in range(10):\n","            a_new = (1/a + (log_N_bar - np.log(N_bar) + np.log(a) - digamma(a)) / (a**2 * (1/a - polygamma(1, a))))**-1\n","            if np.isnan(a).any():\n","                print('Numerical issues in calculating parameter a')\n","                break\n","            if np.sum(np.abs(a_new - a)) / np.sum(a) < a_epsilon:\n","                a = a_new\n","                break\n","            a = a_new\n","        \n","        # update b using MLE \n","        b = N_bar / a\n","\n","    run_time = datetime.now() - start_time\n","    np.set_printoptions(precision=3)\n","    print('Execution Time:', run_time)\n","    print('\\npi = ', np.exp(pi),'\\n\\nA = ', np.exp(A),'\\n\\na = ', a,'\\n\\nb = ', b,'\\n\\np(Z(t=T, u=0:10)|I) = \\n', np.exp(user_class[:3]))\n","    # save parameters\n","    threshold = '1000'\n","    alpha = str(prior_const)\n","    run = str(r+1)\n","    path = '/content/drive/MyDrive/PhD/Modules/IS6101 Topics in Machine Learning and Optimization/HMM for CF/Data and Parameters/'\n","    np.save(path + 'pi_K_' + str(K) + '_threshold_' + threshold + '_alpha_' + alpha + '_run_' + run, pi)\n","    np.save(path + 'mA_K_' + str(K) + '_threshold_' + threshold + '_alpha_' + alpha + '_run_' + run, A)\n","    np.save(path + 'va_K_' + str(K) + '_threshold_' + threshold + '_alpha_' + alpha + '_run_' + run, a)\n","    np.save(path + 'b_K_' + str(K) + '_threshold_' + threshold + '_alpha_' + alpha + '_run_' + run, b)\n","    np.save(path + 'user_class_K_' + str(K) + '_threshold_' + threshold + '_alpha_' + alpha + '_run_' + run, user_class)\n","\n","    # number of items to recommend\n","    num_items = 5000\n","\n","    # log prob of user each latent class in next period assuming user in Z(t) with log p(Z(t)|I(1:T))\n","    # result is multiplying transitional prob to prob of user in each latent class at time t\n","    # p_z = logdotexp(p_z_i[:,-1], A)\n","    p_z = logdotexp(user_class, A)\n","\n","    # calculate probability that item i is not read in the next time period\n","    p_noti_z = np.power(1 + b[...,np.newaxis] * np.exp(theta), -a[...,np.newaxis])\n","\n","    # calculate rank score of the items likely to appear in next time period\n","    rank_score = -np.exp(p_z) @ p_noti_z\n","\n","    # generate indices of top num_items to recommend which will be unsorted\n","    rec_list = np.argpartition(rank_score, -num_items, axis=-1)[:,-num_items:]\n","\n","    # sort indices by rank score\n","    rec_list_score = np.array([row[rec_list[i,:]] for i, row in enumerate(rank_score)]) # get the scores of items in rec_list\n","    sorted_rec_list = np.array([row[np.flip(np.argsort(rec_list_score[i]))] for i, row in enumerate(rec_list)]) # sort the rec_list based on the score\n","    sorted_rec_list[:10]\n","\n","    # check if item in user history\n","    user_history = np.array([row[:,sorted_rec_list[i]] for i, row in enumerate(users_ds)]) # get all binary values in user_ds corresponding to the item in rec_list for each user in each time period\n","    user_history = np.array([np.sum(user, axis=0) for user in user_history]).squeeze() # get boolean array indicating whether each item in sorted_rec_list is in user history (assumes user only has each item at most once)\n","    if user_history.max() > 1: print('There are repeated ratings of a movie by at least one user')\n","    # print(user_history.shape)\n","\n","    # filter sorted_rec_list for items not in user history\n","    filtered_rec_list = [row[np.logical_not(user_history[i])] for i, row in enumerate(sorted_rec_list)] # each user's list will not have the same amount of items as it depends on user history\n","    # get multi-hot encoding of top N recommended movies for the next period\n","\n","    mlb = MultiLabelBinarizer(range(N), sparse_output=True) # prediction done on based on one hot encoding indexing i.e. starting index is 0\n","    # top_5_list = mlb.fit_transform(filtered_rec_list) \n","    top_5_list = [mlb.fit_transform([user[:5]]) for user in filtered_rec_list] # convert top 5 list to one hot encoding\n","    # print(np.shape(top_5_list), top_5_list[0].sum()) # top 5 list means sum = 5\n","    top_10_list = [mlb.fit_transform([user[:10]]) for user in filtered_rec_list] \n","    # print(np.shape(top_10_list), top_10_list[0].sum())\n","\n","    # test how many of top N recommended movies appear in user's rated list of movies in the test period\n","    positive_top_5 = [rec_user.multiply(test_ds[i]) for i, rec_user in enumerate(top_5_list)] # get (#users,#items) boolean vectors indicating whether recommended movie was rating in test period\n","    users_result_top_5 = [row.sum() for row in positive_top_5] # get list of positive matches per user\n","    all_result_top_5 = np.sum(users_result_top_5) # total number of positive matches across all users\n","\n","    positive_top_10 = [rec_user.multiply(test_ds[i]) for i, rec_user in enumerate(top_10_list)] \n","    users_result_top_10 = [row.sum() for row in positive_top_10] # get list of positive matches per user\n","    all_result_top_10 = np.sum(users_result_top_10) # total number of positive matches across all users\n","\n","    test_num_movies_rated = np.sum(test_ds).sum()\n","\n","    # print(all_result_top_5, all_result_top_10, test_num_movies_rated)\n","\n","    # output results to excel via pandas df\n","    dict_result = {'# Ratings Threshold':threshold, '# Users':U, '# Movies':N, 'K':K, 'T': T, 't_predict':t_predict,\n","                'Dirichlet Prior Parameter':alpha, 'Run':run, 'Convergence epsilon': epsilon,\n","                'Log Likelihood':old_likelihood, 'Iterations':iteration,'Time (min)':run_time*24*60,\n","                'Avg Time per iteration (s)':run_time*24*60*60/iteration, \n","                '# movies rated in test period': test_num_movies_rated, \n","                'Total +ve for top 5':all_result_top_5, \n","                'Precision of top 5':all_result_top_5/(5*U),\n","                'Recall of top 5':all_result_top_5/test_num_movies_rated,\n","                'Total +ve for top 10':all_result_top_10,\n","                'Precision of top 10':all_result_top_10/(10*U),\n","                'Recall of top 10':all_result_top_10/test_num_movies_rated\n","                }\n","    df_result = pd.DataFrame(data=dict_result, index=[0])\n","    print(df_result)\n","\n","    table_path = '/content/drive/MyDrive/PhD/Modules/IS6101 Topics in Machine Learning and Optimization/HMM for CF/Report/Table.xlsx'\n","    df_table = pd.read_excel(table_path)\n","    df_table = pd.concat([df_table ,df_result], ignore_index=True)\n","    df_table.to_excel(table_path, index=False)"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0 : log likelihood = -4796912.726427405\n","Iteration 1 : log likelihood = -3969056.0823254026\n","Iteration 2 : log likelihood = -3886982.5048903986\n","Iteration 3 : log likelihood = -3841325.657217962\n","Iteration 4 : log likelihood = -3815055.323419285\n","Iteration 5 : log likelihood = -3798422.849588177\n","Iteration 6 : log likelihood = -3786711.6386238015\n","Iteration 7 : log likelihood = -3778137.79837009\n","Iteration 8 : log likelihood = -3771575.7347250134\n","Iteration 9 : log likelihood = -3766468.7867676285\n","Iteration 10 : log likelihood = -3762436.327564114\n","Iteration 11 : log likelihood = -3759111.2267586133\n","Iteration 12 : log likelihood = -3756309.557142806\n","Iteration 13 : log likelihood = -3753945.8201048267\n","Iteration 14 : log likelihood = -3751921.7065121294\n","Iteration 15 : log likelihood = -3750165.7890330385\n","Iteration 16 : log likelihood = -3748619.0725070373\n","Iteration 17 : log likelihood = -3747239.2522660876\n","Iteration 18 : log likelihood = -3746005.322325865\n","Iteration 19 : log likelihood = -3744879.26030334\n","Iteration 20 : log likelihood = -3743856.4175204816\n","Iteration 21 : log likelihood = -3742922.178053184\n","Iteration 22 : log likelihood = -3742065.733018984\n","Iteration 23 : log likelihood = -3741289.522557887\n","Iteration 24 : log likelihood = -3740580.974571967\n","Iteration 25 : log likelihood = -3739928.295933023\n","Iteration 26 : log likelihood = -3739323.7896011956\n","Iteration 27 : log likelihood = -3738763.3647319586\n","Iteration 28 : log likelihood = -3738242.485301134\n","Iteration 29 : log likelihood = -3737756.8196846447\n","Iteration 30 : log likelihood = -3737301.302914378\n","Iteration 31 : log likelihood = -3736873.547076877\n","Iteration 32 : log likelihood = -3736472.6486714575\n","Iteration 33 : log likelihood = -3736095.8703163075\n","Iteration 34 : log likelihood = -3735739.1837990587 \n","\n","Convergence attained \n","\n","Execution Time: 0:20:05.450077\n","\n","pi =  [0.097 0.836 0.002 0.006 0.014 0.013 0.004 0.009 0.004 0.016] \n","\n","A =  [[1.561e-01 3.157e-01 1.174e-01 2.003e-02 1.016e-02 1.711e-01 1.136e-01\n","  9.905e-03 3.473e-03 8.261e-02]\n"," [1.883e-02 7.490e-01 1.269e-01 1.065e-03 8.277e-04 8.645e-03 8.240e-02\n","  8.331e-04 1.434e-03 1.013e-02]\n"," [1.795e-02 2.244e-01 6.055e-01 1.982e-03 1.174e-03 1.539e-02 2.435e-02\n","  3.883e-03 2.418e-03 1.029e-01]\n"," [2.290e-02 2.376e-01 2.523e-02 1.290e-01 2.093e-02 1.478e-01 1.477e-01\n","  5.004e-02 5.254e-02 1.664e-01]\n"," [1.880e-01 5.878e-02 8.651e-02 3.383e-02 1.428e-01 1.273e-01 8.588e-02\n","  4.174e-02 6.594e-02 1.693e-01]\n"," [4.255e-02 1.977e-02 2.899e-02 5.997e-03 8.488e-03 7.485e-01 1.010e-01\n","  5.657e-03 2.156e-03 3.680e-02]\n"," [1.662e-02 2.174e-02 1.568e-02 4.486e-03 2.094e-03 1.511e-01 6.309e-01\n","  2.400e-03 2.023e-03 1.530e-01]\n"," [8.713e-02 3.163e-01 7.622e-02 9.697e-02 1.407e-02 9.521e-02 6.603e-02\n","  1.672e-04 9.703e-02 1.508e-01]\n"," [5.890e-02 1.024e-01 8.356e-02 1.550e-02 1.210e-02 1.876e-01 2.350e-01\n","  4.618e-02 7.595e-02 1.828e-01]\n"," [5.387e-02 1.105e-01 2.539e-02 6.355e-03 7.797e-03 1.263e-01 3.569e-01\n","  9.995e-04 2.659e-03 3.093e-01]] \n","\n","a =  [0.017 0.118 0.055 0.436 0.456 0.039 0.075 1.008 1.483 0.035] \n","\n","b =  [6.470e+01 1.107e+02 7.185e+01 3.456e-02 3.428e-02 9.915e+01 7.525e+01\n"," 3.420e-02 3.191e-02 6.161e+01] \n","\n","p(Z(t=T, u=0:10)|I) = \n"," [[1.342e-031 2.990e-069 2.433e-057 9.865e-194 4.508e-189 1.000e+000\n","  2.087e-056 6.888e-193 7.386e-192 5.555e-052]\n"," [7.892e-013 1.090e-023 4.056e-016 3.785e-021 4.977e-019 1.000e+000\n","  7.360e-011 7.606e-021 1.501e-021 7.841e-014]\n"," [5.246e-014 1.710e-021 6.486e-013 2.941e-028 7.215e-027 1.000e+000\n","  8.722e-008 1.915e-026 1.945e-028 5.018e-011]]\n","  # Ratings Threshold  # Users  ...  Precision of top 10  Recall of top 10\n","0                1000      874  ...             0.084897          0.045274\n","\n","[1 rows x 20 columns]\n","Iteration 0 : log likelihood = -4824237.908552883\n","Iteration 1 : log likelihood = -3981347.613491401\n","Iteration 2 : log likelihood = -3877534.6907431954\n","Iteration 3 : log likelihood = -3828316.2206191537\n","Iteration 4 : log likelihood = -3804594.938736559\n","Iteration 5 : log likelihood = -3790826.3146457844\n","Iteration 6 : log likelihood = -3781469.3708607797\n","Iteration 7 : log likelihood = -3774124.8141794223\n","Iteration 8 : log likelihood = -3767996.3346616565\n","Iteration 9 : log likelihood = -3762597.3108986327\n","Iteration 10 : log likelihood = -3757955.5875457753\n","Iteration 11 : log likelihood = -3753981.183072898\n","Iteration 12 : log likelihood = -3750584.655364799\n","Iteration 13 : log likelihood = -3747660.470055982\n","Iteration 14 : log likelihood = -3745113.32394209\n","Iteration 15 : log likelihood = -3742876.525011048\n","Iteration 16 : log likelihood = -3740866.1806600443\n","Iteration 17 : log likelihood = -3739056.198163043\n","Iteration 18 : log likelihood = -3737429.00338992\n","Iteration 19 : log likelihood = -3735960.116047093\n","Iteration 20 : log likelihood = -3734611.126878209\n","Iteration 21 : log likelihood = -3733361.582203664\n","Iteration 22 : log likelihood = -3732203.4564374574\n","Iteration 23 : log likelihood = -3731129.3401166466\n","Iteration 24 : log likelihood = -3730138.1134339436\n","Iteration 25 : log likelihood = -3729206.0456591705\n","Iteration 26 : log likelihood = -3728336.3574930057\n","Iteration 27 : log likelihood = -3727523.3522374462\n","Iteration 28 : log likelihood = -3726756.350423614\n","Iteration 29 : log likelihood = -3726028.446816576\n","Iteration 30 : log likelihood = -3725335.2485230435\n","Iteration 31 : log likelihood = -3724666.774742429\n","Iteration 32 : log likelihood = -3724036.526357222\n","Iteration 33 : log likelihood = -3723442.0354578397\n","Iteration 34 : log likelihood = -3722882.657188727\n","Iteration 35 : log likelihood = -3722356.429413173\n","Iteration 36 : log likelihood = -3721860.37963141\n","Iteration 37 : log likelihood = -3721391.031200954\n","Iteration 38 : log likelihood = -3720945.7396310186\n","Iteration 39 : log likelihood = -3720523.0120417504\n","Iteration 40 : log likelihood = -3720121.7422597725\n","Iteration 41 : log likelihood = -3719740.2244834574\n","Iteration 42 : log likelihood = -3719376.025321618 \n","\n","Convergence attained \n","\n","Execution Time: 0:25:31.824827\n","\n","pi =  [0.005 0.021 0.008 0.022 0.907 0.007 0.002 0.004 0.006 0.019] \n","\n","A =  [[5.043e-01 8.627e-04 1.835e-01 3.174e-02 1.002e-02 1.651e-02 4.222e-03\n","  2.348e-03 2.445e-01 1.974e-03]\n"," [7.166e-02 4.978e-02 1.285e-01 1.409e-01 1.991e-01 1.343e-01 1.362e-01\n","  3.537e-02 6.166e-02 4.258e-02]\n"," [5.381e-02 4.525e-04 7.956e-01 5.607e-02 3.310e-02 1.752e-02 4.709e-03\n","  8.042e-03 2.810e-02 2.606e-03]\n"," [2.402e-01 1.896e-03 5.178e-02 5.871e-01 5.196e-02 3.191e-02 2.995e-03\n","  1.714e-03 2.816e-02 2.225e-03]\n"," [8.759e-03 1.248e-03 2.258e-02 9.394e-02 8.569e-01 8.285e-03 1.103e-03\n","  2.498e-03 3.914e-03 7.993e-04]\n"," [2.036e-01 2.506e-02 1.403e-01 2.309e-01 1.396e-01 1.605e-02 5.737e-02\n","  2.164e-02 1.483e-01 1.730e-02]\n"," [1.465e-01 3.131e-02 1.565e-01 9.453e-02 9.870e-02 6.519e-02 1.081e-01\n","  7.788e-02 2.206e-01 7.674e-04]\n"," [7.791e-02 9.383e-02 1.291e-01 1.702e-01 1.683e-01 1.333e-01 7.958e-02\n","  2.319e-02 1.073e-01 1.740e-02]\n"," [3.515e-01 2.519e-03 6.175e-02 2.593e-02 9.379e-03 1.927e-02 5.145e-03\n","  3.439e-03 5.186e-01 2.414e-03]\n"," [1.017e-01 1.372e-01 9.934e-02 1.090e-01 1.511e-01 1.246e-01 1.363e-02\n","  1.735e-01 6.410e-02 2.594e-02]] \n","\n","a =  [0.057 0.698 0.038 0.052 0.118 0.014 0.338 0.103 0.039 0.78 ] \n","\n","b =  [8.253e+01 2.695e-02 9.968e+01 1.022e+02 1.070e+02 3.213e+01 2.867e-02\n"," 2.910e-01 7.355e+01 2.742e-02] \n","\n","p(Z(t=T, u=0:10)|I) = \n"," [[1.189e-049 2.020e-203 1.000e+000 3.953e-063 1.510e-062 3.009e-061\n","  1.160e-200 5.514e-110 1.087e-057 1.056e-203]\n"," [6.676e-014 4.165e-027 1.000e+000 1.234e-020 2.992e-023 7.457e-016\n","  3.462e-024 3.393e-017 5.164e-015 1.535e-026]\n"," [1.312e-011 4.169e-034 1.000e+000 7.823e-023 1.221e-021 1.818e-015\n","  6.691e-030 1.039e-021 1.278e-013 2.363e-034]]\n","  # Ratings Threshold  # Users  ...  Precision of top 10  Recall of top 10\n","0                1000      874  ...             0.079519          0.042406\n","\n","[1 rows x 20 columns]\n","Iteration 0 : log likelihood = -4808750.437207019\n","Iteration 1 : log likelihood = -3985710.8934036493\n","Iteration 2 : log likelihood = -3909093.302437498\n","Iteration 3 : log likelihood = -3855335.776383022\n","Iteration 4 : log likelihood = -3814723.1760405\n","Iteration 5 : log likelihood = -3787822.6351407254\n","Iteration 6 : log likelihood = -3770128.6394440243\n","Iteration 7 : log likelihood = -3757542.262230563\n","Iteration 8 : log likelihood = -3748094.0312259076\n","Iteration 9 : log likelihood = -3740649.0113732927\n","Iteration 10 : log likelihood = -3734674.766326488\n","Iteration 11 : log likelihood = -3729823.536976906\n","Iteration 12 : log likelihood = -3725760.808087545\n","Iteration 13 : log likelihood = -3722242.327544224\n","Iteration 14 : log likelihood = -3719118.02578717\n","Iteration 15 : log likelihood = -3716332.6234403136\n","Iteration 16 : log likelihood = -3713885.227214421\n","Iteration 17 : log likelihood = -3711680.4025068027\n","Iteration 18 : log likelihood = -3709707.708537974\n","Iteration 19 : log likelihood = -3707958.558981767\n","Iteration 20 : log likelihood = -3706401.140578889\n","Iteration 21 : log likelihood = -3705001.6115004653\n","Iteration 22 : log likelihood = -3703740.5544524915\n","Iteration 23 : log likelihood = -3702601.3838366773\n","Iteration 24 : log likelihood = -3701565.761784408\n","Iteration 25 : log likelihood = -3700616.4991165707\n","Iteration 26 : log likelihood = -3699729.23144078\n","Iteration 27 : log likelihood = -3698903.1124637555\n","Iteration 28 : log likelihood = -3698139.1831823173\n","Iteration 29 : log likelihood = -3697429.858765224\n","Iteration 30 : log likelihood = -3696762.15141206\n","Iteration 31 : log likelihood = -3696138.6808864768\n","Iteration 32 : log likelihood = -3695555.42186372\n","Iteration 33 : log likelihood = -3695008.603010568\n","Iteration 34 : log likelihood = -3694495.084954351\n","Iteration 35 : log likelihood = -3694011.9407697544\n","Iteration 36 : log likelihood = -3693556.9912663703\n","Iteration 37 : log likelihood = -3693128.0586958257\n","Iteration 38 : log likelihood = -3692722.405398977\n","Iteration 39 : log likelihood = -3692337.3875422496\n","Iteration 40 : log likelihood = -3691971.4816337544 \n","\n","Convergence attained \n","\n","Execution Time: 0:23:38.872819\n","\n","pi =  [6.651e-03 1.119e-02 6.370e-01 3.898e-03 6.164e-04 2.693e-01 5.832e-03\n"," 2.217e-02 7.584e-03 3.573e-02] \n","\n","A =  [[0.641 0.036 0.004 0.067 0.109 0.039 0.005 0.02  0.023 0.056]\n"," [0.282 0.06  0.034 0.091 0.103 0.108 0.018 0.126 0.094 0.084]\n"," [0.001 0.003 0.675 0.007 0.002 0.083 0.002 0.124 0.1   0.002]\n"," [0.051 0.014 0.006 0.4   0.236 0.042 0.002 0.081 0.035 0.133]\n"," [0.227 0.022 0.011 0.021 0.179 0.048 0.005 0.027 0.021 0.44 ]\n"," [0.051 0.019 0.298 0.023 0.024 0.355 0.003 0.134 0.059 0.033]\n"," [0.047 0.203 0.039 0.023 0.093 0.164 0.074 0.184 0.108 0.065]\n"," [0.04  0.01  0.017 0.096 0.02  0.034 0.001 0.737 0.023 0.022]\n"," [0.096 0.028 0.517 0.027 0.035 0.045 0.004 0.18  0.061 0.008]\n"," [0.337 0.023 0.018 0.014 0.061 0.036 0.004 0.014 0.013 0.48 ]] \n","\n","a =  [0.04  0.013 0.082 0.028 0.023 0.028 0.549 0.071 0.018 0.031] \n","\n","b =  [9.121e+01 3.771e+01 9.363e+01 6.581e+01 6.161e+01 1.396e+02 4.039e-02\n"," 1.068e+02 6.777e+01 6.678e+01] \n","\n","p(Z(t=T, u=0:10)|I) = \n"," [[1.633e-015 3.904e-029 3.361e-081 4.008e-074 5.832e-044 1.000e+000\n","  4.131e-181 2.347e-052 2.367e-043 8.726e-073]\n"," [1.000e+000 5.545e-009 1.963e-029 1.274e-017 5.114e-008 4.469e-011\n","  4.183e-020 1.725e-022 1.226e-014 1.043e-013]\n"," [1.000e+000 8.058e-010 4.142e-026 5.625e-018 2.709e-007 5.033e-011\n","  7.258e-029 1.943e-019 2.473e-011 9.731e-013]]\n","  # Ratings Threshold  # Users  ...  Precision of top 10  Recall of top 10\n","0                1000      874  ...             0.075286          0.040149\n","\n","[1 rows x 20 columns]\n","Iteration 0 : log likelihood = -4805777.102236589\n","Iteration 1 : log likelihood = -3971860.5002527134\n","Iteration 2 : log likelihood = -3918127.1836430416\n","Iteration 3 : log likelihood = -3883202.45392633\n","Iteration 4 : log likelihood = -3851988.861664303\n","Iteration 5 : log likelihood = -3829603.565705506\n","Iteration 6 : log likelihood = -3815406.8870768836\n","Iteration 7 : log likelihood = -3805016.9281203216\n","Iteration 8 : log likelihood = -3796948.3250441067\n","Iteration 9 : log likelihood = -3790454.8268338516\n","Iteration 10 : log likelihood = -3785099.7635019952\n","Iteration 11 : log likelihood = -3780585.910640328\n","Iteration 12 : log likelihood = -3776853.254882138\n","Iteration 13 : log likelihood = -3773654.4863348077\n","Iteration 14 : log likelihood = -3770864.4709395627\n","Iteration 15 : log likelihood = -3768368.2792431777\n","Iteration 16 : log likelihood = -3766115.148249452\n","Iteration 17 : log likelihood = -3764038.34787751\n","Iteration 18 : log likelihood = -3762158.365124056\n","Iteration 19 : log likelihood = -3760454.679879121\n","Iteration 20 : log likelihood = -3758876.81337305\n","Iteration 21 : log likelihood = -3757406.177777096\n","Iteration 22 : log likelihood = -3756029.613334005\n","Iteration 23 : log likelihood = -3754729.69074795\n","Iteration 24 : log likelihood = -3753505.3151127654\n","Iteration 25 : log likelihood = -3752346.591350483\n","Iteration 26 : log likelihood = -3751245.6003503585\n","Iteration 27 : log likelihood = -3750181.955307706\n","Iteration 28 : log likelihood = -3749135.132867109\n","Iteration 29 : log likelihood = -3748127.614066562\n","Iteration 30 : log likelihood = -3747158.3248426714\n","Iteration 31 : log likelihood = -3746215.622860815\n","Iteration 32 : log likelihood = -3745288.89804004\n","Iteration 33 : log likelihood = -3744355.1705618096\n","Iteration 34 : log likelihood = -3743441.003960543\n","Iteration 35 : log likelihood = -3742548.146833811\n","Iteration 36 : log likelihood = -3741663.5056251334\n","Iteration 37 : log likelihood = -3740794.2966318303\n","Iteration 38 : log likelihood = -3739958.433598701\n","Iteration 39 : log likelihood = -3739150.4336403585\n","Iteration 40 : log likelihood = -3738367.3847616264\n","Iteration 41 : log likelihood = -3737608.590631477\n","Iteration 42 : log likelihood = -3736870.614767673\n","Iteration 43 : log likelihood = -3736142.4357369505\n","Iteration 44 : log likelihood = -3735432.753314071\n","Iteration 45 : log likelihood = -3734756.6431495068\n","Iteration 46 : log likelihood = -3734106.804935851\n","Iteration 47 : log likelihood = -3733477.0199369597\n","Iteration 48 : log likelihood = -3732864.5297267055\n","Iteration 49 : log likelihood = -3732271.9765387694\n","Iteration 50 : log likelihood = -3731698.273379278\n","Iteration 51 : log likelihood = -3731142.6900971364\n","Iteration 52 : log likelihood = -3730600.4575358704\n","Iteration 53 : log likelihood = -3730081.220054305\n","Iteration 54 : log likelihood = -3729583.9817977594\n","Iteration 55 : log likelihood = -3729105.609550409\n","Iteration 56 : log likelihood = -3728645.542787047\n","Iteration 57 : log likelihood = -3728203.2443538774\n","Iteration 58 : log likelihood = -3727776.430112844\n","Iteration 59 : log likelihood = -3727361.47762413\n","Iteration 60 : log likelihood = -3726954.155618361\n","Iteration 61 : log likelihood = -3726556.826217943\n","Iteration 62 : log likelihood = -3726173.191001081\n","Iteration 63 : log likelihood = -3725801.906223184 \n","\n","Convergence attained \n","\n","Execution Time: 0:36:36.023485\n","\n","pi =  [0.545 0.001 0.004 0.003 0.153 0.236 0.004 0.045 0.004 0.005] \n","\n","A =  [[1.978e-01 6.618e-03 4.681e-02 3.800e-03 9.091e-02 4.290e-01 3.151e-03\n","  1.662e-01 9.648e-03 4.609e-02]\n"," [7.855e-02 8.513e-02 1.394e-02 4.614e-02 3.606e-01 1.255e-01 4.611e-02\n","  1.056e-01 6.260e-02 7.582e-02]\n"," [7.677e-02 1.231e-02 5.138e-01 4.993e-03 4.918e-02 1.285e-02 7.335e-03\n","  6.865e-02 2.879e-03 2.513e-01]\n"," [8.473e-02 1.189e-01 6.418e-02 3.836e-02 2.571e-01 1.946e-01 2.294e-02\n","  1.084e-01 1.022e-02 1.006e-01]\n"," [1.350e-02 2.076e-03 9.120e-03 1.336e-03 8.349e-01 1.652e-02 8.854e-04\n","  2.827e-02 1.551e-03 9.180e-02]\n"," [4.562e-02 4.693e-03 5.897e-03 1.859e-03 1.332e-01 4.887e-01 8.777e-04\n","  3.113e-01 2.481e-03 5.276e-03]\n"," [8.443e-02 1.249e-01 5.532e-02 2.135e-01 8.881e-02 2.964e-02 6.833e-02\n","  9.760e-02 1.392e-01 9.832e-02]\n"," [1.939e-02 5.110e-03 1.199e-02 2.233e-03 1.812e-01 1.195e-01 6.076e-04\n","  6.485e-01 2.108e-03 9.345e-03]\n"," [1.271e-01 1.988e-02 5.481e-02 1.040e-01 2.518e-01 1.091e-01 1.127e-02\n","  1.867e-01 1.611e-02 1.192e-01]\n"," [1.249e-02 6.732e-04 1.186e-01 9.553e-04 2.258e-02 3.772e-03 6.316e-04\n","  1.264e-02 9.663e-04 8.267e-01]] \n","\n","a =  [0.017 0.32  0.018 0.688 0.113 0.045 1.011 0.055 0.398 0.066] \n","\n","b =  [7.690e+01 1.793e-02 1.015e+02 1.794e-02 9.761e+01 1.016e+02 2.030e-02\n"," 1.054e+02 4.100e-02 8.201e+01] \n","\n","p(Z(t=T, u=0:10)|I) = \n"," [[5.214e-058 2.881e-221 1.000e+000 8.764e-232 4.236e-067 2.681e-089\n","  1.491e-225 5.900e-047 1.404e-204 4.722e-050]\n"," [1.049e-013 8.951e-020 9.673e-001 1.836e-023 1.224e-020 3.488e-023\n","  1.099e-020 2.156e-016 1.615e-021 3.273e-002]\n"," [1.261e-014 1.725e-031 9.536e-001 7.122e-032 2.542e-017 3.114e-021\n","  2.218e-031 3.547e-014 2.063e-028 4.645e-002]]\n","  # Ratings Threshold  # Users  ...  Precision of top 10  Recall of top 10\n","0                1000      874  ...             0.045652          0.024346\n","\n","[1 rows x 20 columns]\n","Iteration 0 : log likelihood = -4808250.182119947\n","Iteration 1 : log likelihood = -3964640.241895453\n","Iteration 2 : log likelihood = -3880901.0720788673\n","Iteration 3 : log likelihood = -3840540.1842059544\n","Iteration 4 : log likelihood = -3817493.954500169\n","Iteration 5 : log likelihood = -3801199.7649643905\n","Iteration 6 : log likelihood = -3789374.4807118964\n","Iteration 7 : log likelihood = -3780365.583522631\n","Iteration 8 : log likelihood = -3773123.290880429\n","Iteration 9 : log likelihood = -3767267.654659568\n","Iteration 10 : log likelihood = -3762457.815631925\n","Iteration 11 : log likelihood = -3758494.2274985854\n","Iteration 12 : log likelihood = -3755137.1058727726\n","Iteration 13 : log likelihood = -3752247.5557245053\n","Iteration 14 : log likelihood = -3749730.672134307\n","Iteration 15 : log likelihood = -3747525.365177294\n","Iteration 16 : log likelihood = -3745566.465505308\n","Iteration 17 : log likelihood = -3743813.0361716705\n","Iteration 18 : log likelihood = -3742216.299444605\n","Iteration 19 : log likelihood = -3740752.2057776707\n","Iteration 20 : log likelihood = -3739407.461987397\n","Iteration 21 : log likelihood = -3738174.728336205\n","Iteration 22 : log likelihood = -3737052.555982419\n","Iteration 23 : log likelihood = -3736019.2572078845\n","Iteration 24 : log likelihood = -3735046.524009023\n","Iteration 25 : log likelihood = -3734129.7099526823\n","Iteration 26 : log likelihood = -3733267.507579709\n","Iteration 27 : log likelihood = -3732464.456502607\n","Iteration 28 : log likelihood = -3731718.474410523\n","Iteration 29 : log likelihood = -3731018.222828758\n","Iteration 30 : log likelihood = -3730353.083995251\n","Iteration 31 : log likelihood = -3729729.404539303\n","Iteration 32 : log likelihood = -3729141.548835739\n","Iteration 33 : log likelihood = -3728583.951445173\n","Iteration 34 : log likelihood = -3728054.065408071\n","Iteration 35 : log likelihood = -3727549.210390398\n","Iteration 36 : log likelihood = -3727066.2596925898\n","Iteration 37 : log likelihood = -3726603.788086311\n","Iteration 38 : log likelihood = -3726162.5880409167\n","Iteration 39 : log likelihood = -3725743.715800456\n","Iteration 40 : log likelihood = -3725346.0197566077\n","Iteration 41 : log likelihood = -3724967.714908306\n","Iteration 42 : log likelihood = -3724606.4497672594 \n","\n","Convergence attained \n","\n","Execution Time: 0:24:52.779257\n","\n","pi =  [0.008 0.004 0.011 0.477 0.002 0.007 0.006 0.012 0.47  0.001] \n","\n","A =  [[4.736e-01 4.905e-03 2.151e-02 2.624e-02 4.701e-03 1.293e-01 3.167e-01\n","  7.976e-04 1.937e-02 2.900e-03]\n"," [2.875e-02 8.339e-02 2.074e-01 2.193e-01 2.475e-02 2.267e-01 3.586e-02\n","  4.889e-02 7.090e-02 5.407e-02]\n"," [1.500e-01 5.961e-03 5.713e-01 4.395e-02 2.956e-03 1.234e-01 2.041e-02\n","  8.824e-04 7.957e-02 1.506e-03]\n"," [2.680e-02 4.161e-03 4.266e-02 3.800e-01 7.224e-03 7.920e-02 3.157e-02\n","  2.249e-03 4.226e-01 3.513e-03]\n"," [1.031e-01 6.496e-02 7.571e-02 2.236e-01 9.022e-02 1.646e-01 8.738e-02\n","  7.193e-02 5.865e-02 5.989e-02]\n"," [9.215e-02 4.693e-03 2.328e-02 4.545e-02 3.200e-03 6.998e-01 1.123e-01\n","  4.860e-04 1.533e-02 3.294e-03]\n"," [2.919e-02 2.010e-03 1.810e-02 4.720e-02 9.232e-04 2.521e-01 6.422e-01\n","  9.823e-04 6.913e-03 4.394e-04]\n"," [4.392e-02 2.360e-02 2.184e-01 3.368e-02 5.634e-02 7.125e-02 5.482e-02\n","  1.134e-01 2.677e-01 1.169e-01]\n"," [4.265e-03 2.452e-03 1.105e-01 9.551e-02 4.990e-04 1.529e-02 4.747e-03\n","  1.029e-03 7.646e-01 1.103e-03]\n"," [6.452e-02 6.111e-02 7.384e-02 6.643e-02 8.907e-03 2.077e-01 1.654e-01\n","  6.782e-02 2.084e-01 7.589e-02]] \n","\n","a =  [0.031 0.712 0.044 0.045 0.594 0.045 0.042 0.915 0.11  0.818] \n","\n","b =  [6.493e+01 2.566e-02 9.140e+01 6.916e+01 3.021e-02 1.020e+02 8.012e+01\n"," 3.109e-02 1.139e+02 3.642e-02] \n","\n","p(Z(t=T, u=0:10)|I) = \n"," [[1.564e-076 5.351e-201 2.054e-058 1.424e-043 2.856e-201 1.000e+000\n","  1.462e-061 3.230e-204 1.466e-065 1.329e-195]\n"," [6.955e-021 2.154e-021 3.872e-019 1.250e-016 9.038e-023 1.000e+000\n","  7.829e-009 6.202e-022 1.065e-024 8.613e-021]\n"," [1.511e-016 1.472e-029 5.317e-018 5.238e-015 1.336e-030 1.000e+000\n","  1.041e-008 9.058e-032 1.087e-023 9.340e-030]]\n","  # Ratings Threshold  # Users  ...  Precision of top 10  Recall of top 10\n","0                1000      874  ...             0.077117          0.041125\n","\n","[1 rows x 20 columns]\n"]}]}]}